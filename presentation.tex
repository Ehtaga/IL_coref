\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{libertine}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{lmodern}

\mode<presentation>
{
  \usetheme{Madrid}
  \usecolortheme{beaver}
  \usefonttheme{default}
  \setbeamertemplate{navigation symbols}{}
  \setbeamertemplate{caption}[numbered]
} 


%\usepackage{pgfpages}
%\pgfpagesuselayout{resize to}[%
%  physical paper width=8in, physical paper height=6in]

\title[Mais qui est ce \og \textit{il} \fg{} ?]{Détermination du caractère anaphorique\\ du pronom personnel \og{}\textit{il}\fg{}}
\subtitle{\textit{Mais qui est ce \og il \fg{} ?}}
\author{Agathe \textsc{Mollé}}
\institute{Université de Nantes}
\date{3 mai 2013}
%TODO mail + Nicolas Hernandez

\begin{document}

\begin{frame}
  \titlepage
  \begin{center}
  \verb!agathe.molle@etu.univ-nantes.fr!
  \vskip 1cm
  Encadrant : Nicolas \textsc{Hernandez}
  \end{center}
\end{frame}

\begin{frame}{Plan}
  \tableofcontents
\end{frame}


\section{Contexte}

\begin{frame}{Plan}
  \tableofcontents[currentsection]
\end{frame}

\begin{frame}{Résolution d'anaphores}
\begin{block}{Anaphore}
Expression désignant une entité : \og \textit{il} \fg{}, \og \textit{cette maison} \fg{} \\
Possède un ou plusieurs antécédent(s).\\
\end{block}
Ex : \og \textit{Vendredi, \textbf{M. Edmond Maire} a réuni la presse pour apporter \underline{\textbf{son}} soutien à \underline{\textbf{sa}} fédération des cheminots} \fg{}
\vskip 1cm
\textbf{Problématique :} trouver l'antécédent.\\
\end{frame}

\begin{frame}{Caractère co-référentiel d'une expression}
L'une des étapes de la résolution d'anaphore est de déterminer le caractère co-référentiel (anaphorique) d'une expression.
\vskip 0.5cm
Intérêt des pronoms : fréquents et facilement identifiables.
\vskip 0.5cm
On s'intéresse au pronom personnel \og \textit{il} \fg{}.\\
Celui-ci peut s'avérer :
\begin{itemize}
  \item anaphorique \og{}\textit{\underline{il} ne pouvait entrer ainsi dans un conflit ouvert}\fg{}
  \item impersonnel \og{}\textit{\underline{il} est temps de mettre un terme à la grève}\fg{}
\end{itemize}
\end{frame}

\begin{frame}{Objectif}
Actuellement :
\begin{itemize}
  \item De nombreuses approches traitant du \og \textit{it} \fg{} anglais : à base de règles (Lappin et Leass, 1994) ou bien d'apprentissage automatique (Li et al., 2009 - Bergsma et Yarowski, 2011).\\
  $\implies$ s'appuient sur la structure syntaxique de l'anglais donc pas aisément portables
  \item A notre connaissance, une seule étude pour le français : à base de règles (Danlos, 2005)
\end{itemize}
\vskip 1cm
\textbf{Objectif :} déterminer le caractère anaphorique du \og \textit{il} \fg{} à l'aide d'apprentissage automatique supervisé.
\end{frame}

\section{État de l'art}

\begin{frame}{Plan}
  \tableofcontents[currentsection]
\end{frame}

\begin{frame}{ILIMP - Danlos 2005}
\begin{itemize}
  \item ILIMP : outil à base de règles
  \item Pour établir les règles : lister exhaustivement toutes les constructions impersonnelles possibles (lexique-grammaire, Gross 1994)
  \item Règles transformées en patrons linguistiques pour UNITEX :\\
  \begin{itemize}
    \item Ex : \verb!Il[IMP] <être.V:3s> <Adj1:ms> de <V:W>!\\
  reconnaissant \og{}\textit{Il est difficile de résoudre ce problème.}\fg{}
  \end{itemize}
  \item Prétraitement des données : tokénisation + toutes les étiquettes morpho-syntaxiques possibles (dictionnaire DELAF)
\end{itemize}
\end{frame}

\begin{frame}{ILIMP - Danlos 2005 (2)}
\begin{itemize}
  \item Occurrences étiquetées \verb![ANA]! par défaut. Si elles correspondent à un patron : \verb![IMP]!. Pour les cas ambigus : \verb![AMB]!.
  \item Évaluation : sur \textit{Le Monde 1994} (+3 000 000 tokens), précision de 97,5\%
  \item Source des erreurs :
  \begin{itemize}
    \item Pas de désambiguïsation pour l'étiquetage morpho-syntaxique
    \item Toutes les constructions impersonnelles ne sont pas répertoriées
    \item Heuristiques brutales pour éviter la balise \verb![AMB]!
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{NADA - Bergsma et Yarowski 2011}
\begin{itemize}
  \item NADA : Outil à base d'apprentissage automatique supervisé et d'observations statistiques.
  \item Traite du \og \textit{it} \fg{} anglais
  \item 2 types de traits : 
  \begin{itemize}
    \item lexicaux-syntaxiques (extraits sur la phrase entière)
    \item tirés du corpus n-gramme de Google
  \end{itemize}
  \item Évalué sur 3 corpus : BBN, WSJ-2 et ItBank $\implies$ entre 85,1\% et 86,2\%
\end{itemize}
\end{frame}


\section{Corpus de travail}

\begin{frame}{Plan}
  \tableofcontents[currentsection]
\end{frame}

\begin{frame}{Corpus de travail}
\begin{itemize}
  \item Portion du corpus annoté par Tutin et al. (2000) : \textit{Le Monde}, rubrique économie
  \item + de 200 000 mots dont 1176 pronoms \og \textit{il} \fg{} (537 anaphoriques / 631 impersonnels)
  \item Seules les expressions anaphoriques sont annotées $\implies$ on ne garde que les annotations du pronom \og \textit{il} \fg{} et on considère tous les \og \textit{il} \fg{} non annotés comme impersonnels
  \item Division du corpus en 3 parties :
  \begin{itemize}
    \item 10\% : corpus de développement
    \item 10\% : corpus de test (que l'on se réserve pour de futurs travaux)
    \item le reste : corpus d'entraînement
  \end{itemize}
\end{itemize}
\end{frame}


\section{Compilation de traits}

\begin{frame}{Plan}
  \tableofcontents[currentsection]
\end{frame}

\begin{frame}{Traits recensés}
D'après L. Danlos, les constructions impersonnelles reposent sur des conditions tant lexicales que syntaxiques :
\begin{itemize}
  \item \og \textit{Il est \textbf{violet}} \fg{}\footnote{Les exemples mentionnés sont tirés de l'article de L. Danlos (2005)}
  \item \og \textit{Il \textbf{pleut}} \fg{}  
  \item \og \textit{Il est \textbf{probable} que Fred viendra} \fg{} 
  \item \og \textit{Il est \textbf{difficile} \underline{de} résoudre ce problème} \fg{}
   \item \og \textit{Il est \textbf{difficile} \underline{à} résoudre (ce problème)} \fg{} 
\end{itemize}
\vskip 0.2cm
$\implies$ Traits extraits des propriétés sémantiques et syntaxiques de la tête lexicale + de la nature syntaxique du complément.
\begin{alertblock}{Problèmes :}
\begin{itemize}
  \item Comment distinguer la tête lexicale et le complément ?
  \item Comment construire des lexiques suffisamment riches ?
\end{itemize}
\end{alertblock}
\end{frame}

\begin{frame}{Traits (2)}
Autres observations :
\begin{itemize}
  \item des expressions typiquement impersonnelles (\og \textit{quoi qu'il en soit} \fg{}, \og{} \textit{il était une fois} \fg{}, etc).
  \item la présence de déterminants possessifs à la 3\up{ème} personne du singulier (\og \textit{son} \fg{}, \og \textit{sa} \fg{}), du pronom \og \textit{lui} \fg{} , d'autres occurrences de \og \textit{il} \fg{}, etc.
  \item des données extrinsèques au corpus (corpus n-gramme Google)
\end{itemize}
\end{frame}


\section{Expériences}

\begin{frame}{Plan}
  \tableofcontents[currentsection]
\end{frame}

\begin{frame}{Approche}
Approche expérimentée :
\begin{itemize}
  \item Étiquetage de séquences (\textit{sequence labeling})
  \item Outil Wapiti
  \item Classes IMP et ANA
  \item 2 expériences
  \item Prétraitement avec les analyseurs d'Apache OpenNLP
\end{itemize}
\vskip 1cm
Baseline :
\begin{itemize}
  \item Tout étiqueter selon la classe majoritaire, à savoir IMP (53,66\%)
\end{itemize}
\end{frame}

\begin{frame}{Expériences}
Première expérience :
\begin{itemize}
  \item Traits classiques utilisés pour la reconnaissance de segments syntaxiques (\textit{chunks})
  \item Observation du contexte local (formes de surface, étiquettes morpho-syntaxiques, bigrammes, majuscules, etc. dans une fenêtre de 5 tokens)
\end{itemize}
\vskip 0.5cm
Seconde expérience :
\begin{itemize}
  \item Ajout de traits spécifiques à cette tâche
  \item Simplification du problème : au lieu de chercher la tête lexicale, on observe le premier verbe, adjectif ou adverbe suivant l'occurrence
  \item Lexiques non implémentés
  \item Statistiques sur la phrase (présence de possessifs, etc.)
\end{itemize}
\end{frame}

\begin{frame}{Évaluation}
\begin{itemize}
  \item Validation croisée, 10 partitions
  \item Sur le corpus d'entraînement
  \item Mesures utilisées :
  \begin{itemize}
    \item Taux d'occurrences correctement classées (exactitude/\textit{accuracy})
    \item Pour chaque classe :
\[Precision = \frac{Nombre\ d'occurences\ correctement\ classees\ ANA}{Nombre\ d'occurences\ classees\ ANA}\]
\[Rappel = \frac{Nombre\ d'occurences\ correctement\ classees\ ANA}{Nombre\ d'occurences\ annotees\ comme\ anaphoriques}\]
\[F-mesure = \frac{2 * (Precision * Rappel)}{(Precision + Rappel)}\]
  \end{itemize}
\end{itemize}
\end{frame}


\section{Résultats}

\begin{frame}{Plan}
  \tableofcontents[currentsection]
\end{frame}

\begin{frame}{Résultats}
\textbf{Expérience avec les traits classiques de reconnaissance des segments syntaxiques :}

\begin{tabular}[H]{l|lll|lll}
& \multicolumn{3}{c|}{ANA} & \multicolumn{3}{c}{IMP}\\
Exactitude & Précision & Rappel & F-mes. & Précision & Rappel & F-mes.\\
\hline
0,79 & 0,78 & 0,76 & 0,77 & 0,81 & 0,83 & 0,82\\
\hline
\end{tabular}

\vskip 1cm
\textbf{Série d'expériences avec incorporation de nouveaux traits :}

\begin{tabular}[H]{l|lll|lll}
& \multicolumn{3}{c|}{ANA} & \multicolumn{3}{c}{IMP}\\
Exactitude & Précision & Rappel & F-mes. & Précision & Rappel & F-mes.\\
\hline
0,8 & 0.79 & 0.77 & 0.78 & 0.81 & 0.83 & 0.83\\
\hline
\end{tabular}
\end{frame}


\begin{frame}{Interprétation}
\begin{itemize}
  \item La seule observation du contexte local suffit à obtenir des résultats intéressants (79\% d'instances correctement classées)
  \item Les traits ajoutés lors de la seconde expérience ne sont pas concluants : ils n'améliorent presque pas les scores.
  \item Ceci s'explique par une heuristique trop na\"ive pour détecter les têtes lexicales
  \item Les traits relatifs à la présence d'entités spécifiques (possessifs,\ldots) n'améliorent pas les scores car dans ces cas, les traits classiques de la reconnaissance de chunks suffisent
\end{itemize}
\end{frame}


\section{Perspectives et Conclusion}

\begin{frame}{Plan}
  \tableofcontents[currentsection]
\end{frame}

\begin{frame}{Perspectives}
\begin{itemize}
  \item Aborder le problème comme une t\^ache de classification simple
  \item Exploiter la totalité du corpus, afin d'obtenir des proportions plus raisonnables (actuellement 1/5)
  \item Détecter correctement la t\^ete lexicale d'une construction, ainsi que son complément (chunking ?)
  \item Établir des lexiques d'entités ancrant des phrases impersonnelles ou anaphoriques
  \item Utiliser le corpus n-gramme de Google, à l'instar des travaux de Bergsma et Yarowski sur le \og \textit{it} \fg{} anglais 
\end{itemize}
\end{frame}

\begin{frame}{Conclusion}
\begin{itemize}
  \item Résultats encourageants pour une approche à base d'apprentissage automatique supervisé.
  \item La seule observation du contexte local dans une fenêtre de 5 tokens donne 80\% de réussite
  \item Il reste des pistes à explorer + des implémentations à améliorer
\end{itemize}
\end{frame}



\begin{frame}{Questions}
Des questions ?
\end{frame}

%\begin{frame}{Introduction}
%\center
%%\includegraphics[width=8cm]{evolution.jpg}
%\begin{itemize}
%  \item Evolution naturelle
%  \item Croisement et mutation
%  \item Optimiser la sélection
%  \item Intérêt pour l'apprentissage artificiel
%\end{itemize}
%
%%\vskip 1cm
%
%%\begin{block}{Examples}
%%Some examples of commonly used commands and features are included, %to help you get started.
%%\end{block}
%
%\end{frame}
%
%\section{Idée générale}
%
%\begin{frame}{Trois espaces au lieu de deux}
%
%\begin{block}{D'ordinaire, 2 espaces pour l'apprentissage :}
%\begin{itemize}
%	\item Espace des exemples $\mathcal{X}$
%    \item Espace des hypothèses $\mathcal{H}$
%\end{itemize}
%\end{block}
%
%\vskip 1cm
%
%\begin{block}{Idée}
%Introduire un 3\textsuperscript{ème} ensemble :
%\begin{itemize}
%	\item Espace génotypique $\mathcal{G}$
%\end{itemize}
%dans lequel s'effectuent les opérations permettant l'exploration de $\mathcal{H}$
%\end{block}
%
%\end{frame}
%
%\begin{frame}{Processus}
%\begin{enumerate}
%	\item \textbf{Expression :} Projection de la population d'éléments de $\mathcal{G}$ dans l'espace phénotypique $\mathcal{H}$
%    \item \textbf{Mesure de la performance :} Evaluation de la population d'hypothèses
%    \item \textbf{Sélection d'une opération de variation :} Quelle opération va transformer la population dans $\mathcal{G}$ ?
%    \item \textbf{Variation :} Application de l'opération choisie
%\end{enumerate}
%
%\vskip 1cm
%
%Cycle répété jusqu'à évaluation jugée satisfaisante (ou borne de ressources calculatoires atteinte).
%\end{frame}
%
%\section{Approches principales}
%
%\begin{frame}{Approches principales}
%Identifier l'espace $\mathcal{G}$ approprié.
%\begin{itemize}
%	\item \textbf{Algorithmes génétiques} (John Holland, 1975) : alphabet binaire
%    \item \textbf{Stratégies d'évolution} (Rechenberg et Schwefel, 1965) : 
%$\mathbb{R}$
%	\item \textbf{Programmation évolutive} (Fogel, 1966) : automates à états finis (FSA)
%    \item \textbf{Programmation génétique} (Koza, 1992) : arbres décrivant des programmes
%\end{itemize}
%\end{frame}
%
%\section{Conclusion}
%
%\begin{frame}{Coévolution \& Conclusion}
%\center
%%\includegraphics[width=10cm]{pljds16r.jpg}
%\end{frame}

%\section{Some \LaTeX{} Examples}

%\subsection{Tables and Figures}

%\begin{frame}{Tables and Figures}

%\begin{itemize}
%\item Use \texttt{tabular} for basic tables --- see Table~\ref{tab:widgets}, for example.
%\item You can upload a figure (JPEG, PNG or PDF) using the files menu. 
%\item To include it in your document, use the %\texttt{includegraphics} command (see the comment below in the source code).
%\end{itemize}

% Commands to include a figure:
%\begin{figure}
%\includegraphics[width=\textwidth]{your-figure's-file-name}
%\caption{\label{fig:your-figure}Caption goes here.}
%\end{figure}

%\begin{table}
%\centering
%\begin{tabular}{l|r}
%Item & Quantity \\\hline
%Widgets & 42 \\
%Gadgets & 13
%\end{tabular}
%\caption{\label{tab:widgets}An example table.}
%\end{table}

%\end{frame}

%\subsection{Mathematics}

%\begin{frame}{Readable Mathematics}

%Let $X_1, X_2, \ldots, X_n$ be a sequence of independent and identically distributed random variables with $\text{E}[X_i] = \mu$ and $\text{Var}[X_i] = \sigma^2 < \infty$, and let
%$$S_n = \frac{X_1 + X_2 + \cdots + X_n}{n}
%      = \frac{1}{n}\sum_{i}^{n} X_i$$
%denote their mean. Then as $n$ approaches infinity, the random variables $\sqrt{n}(S_n - \mu)$ converge in distribution to a normal $\mathcal{N}(0, \sigma^2)$.

%\end{frame}

\end{document}
